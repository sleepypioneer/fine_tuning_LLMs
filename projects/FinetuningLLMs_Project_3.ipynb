{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sleepypioneer/fine_tuning_LLMs/blob/week_three/projects/FinetuningLLMs_Project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvYvn0PYdsuZ"
      },
      "source": [
        "# Project 3:  LORA Fine Tuning\n",
        "\n",
        "In this project, you will use parameter efficient fine tuning (PEFT) low rank adaptation (LORA) to fine-tune the phi-1.5 model for summarizing scientific papers. For this assignment, we will use `microsoft/phi-1.5` [model](https://huggingface.co/microsoft/phi-1_5) that works on free T4 GPUs with 16GB provided by Google Colab. If you have access to bigger GPUs like A100 with 40GB memory, I encourage you to experiment with bigger and latest LLMs like [Lllama-2](https://huggingface.co/models?search=llama2) or [Mistral](https://huggingface.co/mistralai)\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- [1 - Data Handling](#1)\n",
        "  - [1.1 - Downloading the Data](#1.1)\n",
        "  - [1.2 - Exploring the Data](#1.2)\n",
        "\n",
        "- [2 - Data Preprocessing](#2)\n",
        "  - [2.1 - Restructuring and Tokenizing](#2.1)\n",
        "  - [2.2 - Decoding Example](#2.2)\n",
        "\n",
        "- [3 - Configuring PEFT LORA](#3)\n",
        "  - [3.1 - Downloading and Converting Phi-1.5](#3.1)\n",
        "  - [3.2 - Trainable Parameters](#3.2)\n",
        "\n",
        "- [4 - Training Configuration](#4)\n",
        "\n",
        "- [5 - Model Training](#5)\n",
        "\n",
        "- [6 - Evaluation](#6)\n",
        "\n",
        "- [7 - Real-World Application](#7)\n",
        "\n",
        "- [8 - Conclusion](#8)\n",
        "\n",
        "This project is truly the bleeding edge of generative AI- we are so excited to see where you take this technology.  If you get stuck, make sure to reach out to the course team and your peers for support!\n",
        "\n",
        "Let's get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7LOzjAo7tUMV"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch datasets peft einops trl --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sdYaBwJ_WGt7"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, pipeline\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from trl import SFTTrainer\n",
        "import os\n",
        "import unittest\n",
        "from unittest.mock import patch\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZllPCuXMfns9"
      },
      "source": [
        "<a name='1'></a>\n",
        "# Data Handling\n",
        "\n",
        "Our goal is to fine tune a pretrained model on a dataset gathered by the [Allen Institute for AI](https://allenai.org/).  This dataset, known as [SciTLDR](https://huggingface.co/datasets/allenai/scitldr) contains extreme summaries of scientific content.  Here's a quick description from the dataset card:\n",
        "\n",
        "**SciTLDR: Extreme Summarization of Scientific Documents**\n",
        "\n",
        "SciTLDR is a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SciTLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden.\n",
        "\n",
        "<a name='1.1'></a>\n",
        "## Downloading the Data\n",
        "Let's get started by pulling the dataset from the HuggingFace Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KBEURmuYv0Z4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "094e7552691048b8b8830c1c8b9f486e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b49de8c39974a7d89c09d09f547ecd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/7.56k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a7ea45e29314c3095bbe311dc22ce3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.81k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "372a9667d41c4348bbb7a4c5dd84e741",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c4c405dae1e4901bf32015a22f3685a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.01M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e546a05827e402196a0b0ffafc9c7a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/356k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9c79ce4060449b0884fc187da8d14f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/378k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18501b2014ae4a62b791a76c5995c15f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1992 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5e1ef4659b64304b16596dfb05d80e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/618 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd7c6c841e9d43c2a6b55e25c8301ae9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/619 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['source', 'source_labels', 'rouge_scores', 'paper_id', 'target'],\n",
              "        num_rows: 1992\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['source', 'source_labels', 'rouge_scores', 'paper_id', 'target'],\n",
              "        num_rows: 618\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['source', 'source_labels', 'rouge_scores', 'paper_id', 'target'],\n",
              "        num_rows: 619\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"allenai/scitldr\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTPVqiXihXNU"
      },
      "source": [
        "<a name='1.2'></a>\n",
        "## Exploring the Data\n",
        "Let's take a look at an example from the data.  The `source` and `target` columns are most important to our work here, although the others also contain interesting information.  Don't hesitate to check them out!\n",
        "\n",
        "This dataset has a unique structure:\n",
        "* The source content for each sample is a list of sentences.  These sentences need to be concatenated to construct the full content.\n",
        "* THe target content, which contains the TLDR summary, is a list of strings.  Each of those strings contains a TLDR summary.  In this exercise, we are only using the first TLDR string in the dataset. This is the \"expert\" TLDR, according to the dataset description.\n",
        "\n",
        "Check out the cell below to see these concepts in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VJsofQL-hwcY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Source content:  Due to the success of deep learning to solving a variety of challenging machine learning tasks, \n",
              "there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect. \n",
              "Particularly, the properties of critical points and the landscape around them are of importance to determine the \n",
              "convergence performance of optimization algorithms. In this paper, we provide a necessary and sufficient \n",
              "characterization of the analytical forms for the critical points <span style=\"font-weight: bold\">(</span>as well as global minimizers<span style=\"font-weight: bold\">)</span> of the square loss \n",
              "functions for linear neural networks. We show that the analytical forms of the critical points characterize the \n",
              "values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global \n",
              "minimum. Furthermore, we exploit the analytical forms of the critical points to characterize the landscape \n",
              "properties for the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is\n",
              "that: While the loss function of linear networks has no spurious local minimum, the loss function of \n",
              "one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global \n",
              "minimum.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Source content:  Due to the success of deep learning to solving a variety of challenging machine learning tasks, \n",
              "there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect. \n",
              "Particularly, the properties of critical points and the landscape around them are of importance to determine the \n",
              "convergence performance of optimization algorithms. In this paper, we provide a necessary and sufficient \n",
              "characterization of the analytical forms for the critical points \u001b[1m(\u001b[0mas well as global minimizers\u001b[1m)\u001b[0m of the square loss \n",
              "functions for linear neural networks. We show that the analytical forms of the critical points characterize the \n",
              "values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global \n",
              "minimum. Furthermore, we exploit the analytical forms of the critical points to characterize the landscape \n",
              "properties for the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is\n",
              "that: While the loss function of linear networks has no spurious local minimum, the loss function of \n",
              "one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global \n",
              "minimum.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Target TLDR:  We provide necessary and sufficient analytical forms for the critical points of the square loss \n",
              "functions for various neural networks, and exploit the analytical forms to characterize the landscape properties \n",
              "for the loss functions of these neural networks.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Target TLDR:  We provide necessary and sufficient analytical forms for the critical points of the square loss \n",
              "functions for various neural networks, and exploit the analytical forms to characterize the landscape properties \n",
              "for the loss functions of these neural networks.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from rich import print\n",
        "sample_idx = 0\n",
        "\n",
        "# Concatenate all the source content sentences\n",
        "print(f\"Source content:  {' '.join(dataset['train'][sample_idx]['source'])}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Retrieve the first target TLDR.\n",
        "print(f\"Target TLDR:  {dataset['train'][sample_idx]['target'][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvTX__d1qlKf"
      },
      "source": [
        "<a name='2'></a>\n",
        "# Load pre-trained model and tokenizer\n",
        "\n",
        "We'll be using the tokenizer that was trained in concert with the Phi-1.5 model.  This tokenizer does not come with a `PAD` token, so we will reuse its `EOS` token.  Let's download the tokenizer in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ho49jh9cte-x"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "040c616be74841b79d9e940a965e9329",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)former_sequential.py:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n",
            "- configuration_mixformer_sequential.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df0bb9cb9d334ba3b4548c944b1435ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)former_sequential.py:   0%|          | 0.00/31.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n",
            "- modeling_mixformer_sequential.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        }
      ],
      "source": [
        "model_name='microsoft/phi-1_5'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXfgEvQVgHS6"
      },
      "source": [
        "# Pre-trained model performance\n",
        "\n",
        "Let's look at how the pre-trained model performs for summarization task. Let's structure the prompt as a zero-shot instruction prompt:\n",
        "\n",
        "```text\n",
        "Summarize the following academic content.\n",
        "\n",
        "[source scientific content]\n",
        "\n",
        "Summary:\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A5v7eNhiepw"
      },
      "source": [
        "## Prompt template\n",
        "\n",
        "Let's create a prompt template that uses the source field in the dataset and converts source into an input to the model that includes the instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PNepqbamiQMD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summarize the following academic content.\n",
              "\n",
              "Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising \n",
              "interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the \n",
              "properties of critical points and the landscape around them are of importance to determine the convergence \n",
              "performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of \n",
              "the analytical forms for the critical points <span style=\"font-weight: bold\">(</span>as well as global minimizers<span style=\"font-weight: bold\">)</span> of the square loss functions for linear\n",
              "neural networks. We show that the analytical forms of the critical points characterize the values of the \n",
              "corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. \n",
              "Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for \n",
              "the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While \n",
              "the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear\n",
              "networks with ReLU activation function does have local minimum that is not global minimum.\n",
              "\n",
              "Summary:\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Summarize the following academic content.\n",
              "\n",
              "Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising \n",
              "interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the \n",
              "properties of critical points and the landscape around them are of importance to determine the convergence \n",
              "performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of \n",
              "the analytical forms for the critical points \u001b[1m(\u001b[0mas well as global minimizers\u001b[1m)\u001b[0m of the square loss functions for linear\n",
              "neural networks. We show that the analytical forms of the critical points characterize the values of the \n",
              "corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. \n",
              "Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for \n",
              "the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While \n",
              "the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear\n",
              "networks with ReLU activation function does have local minimum that is not global minimum.\n",
              "\n",
              "Summary:\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt_template = \"\"\"Summarize the following academic content.\\n\n",
        "{source}\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "sample = dataset[\"train\"][0]\n",
        "prompt = prompt_template.format(source=\" \".join(sample[\"source\"]))\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C57Q2qDTjjDs"
      },
      "source": [
        "## Text-generation Pipeline\n",
        "\n",
        "Let's create text generation pipeline using the phi_1.5 model, pass the above prompt as input and evaluate the response of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SUa3-cPCjiiM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summarize the following academic content.\n",
              "\n",
              "Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising \n",
              "interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the \n",
              "properties of critical points and the landscape around them are of importance to determine the convergence \n",
              "performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of \n",
              "the analytical forms for the critical points <span style=\"font-weight: bold\">(</span>as well as global minimizers<span style=\"font-weight: bold\">)</span> of the square loss functions for linear\n",
              "neural networks. We show that the analytical forms of the critical points characterize the values of the \n",
              "corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. \n",
              "Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for \n",
              "the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While \n",
              "the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear\n",
              "networks with ReLU activation function does have local minimum that is not global minimum.\n",
              "\n",
              "Summary:\n",
              "In this study, we explore the properties of critical points and the landscape around them for loss functions in \n",
              "linear neural networks. We demonstrate that the analytical forms of critical points can characterize the values of \n",
              "the corresponding loss functions as well as the necessary and sufficient\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Summarize the following academic content.\n",
              "\n",
              "Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising \n",
              "interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the \n",
              "properties of critical points and the landscape around them are of importance to determine the convergence \n",
              "performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of \n",
              "the analytical forms for the critical points \u001b[1m(\u001b[0mas well as global minimizers\u001b[1m)\u001b[0m of the square loss functions for linear\n",
              "neural networks. We show that the analytical forms of the critical points characterize the values of the \n",
              "corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. \n",
              "Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for \n",
              "the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While \n",
              "the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear\n",
              "networks with ReLU activation function does have local minimum that is not global minimum.\n",
              "\n",
              "Summary:\n",
              "In this study, we explore the properties of critical points and the landscape around them for loss functions in \n",
              "linear neural networks. We demonstrate that the analytical forms of critical points can characterize the values of \n",
              "the corresponding loss functions as well as the necessary and sufficient\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TLDR target: We provide necessary and sufficient analytical forms for the critical points of the square loss \n",
              "functions for various neural networks, and exploit the analytical forms to characterize the landscape properties \n",
              "for the loss functions of these neural networks.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "TLDR target: We provide necessary and sufficient analytical forms for the critical points of the square loss \n",
              "functions for various neural networks, and exploit the analytical forms to characterize the landscape properties \n",
              "for the loss functions of these neural networks.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pipe = pipeline(\"text-generation\",model=model,tokenizer=tokenizer)\n",
        "response = pipe(prompt, do_sample=True, max_new_tokens=50, temperature=0.7)\n",
        "print(response[0][\"generated_text\"])\n",
        "print(\"-----------\")\n",
        "target = \" \".join(sample[\"target\"])\n",
        "print(\"TLDR target: %s\"%target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx7SeJEolEzC"
      },
      "source": [
        "## Restructuring a new column `text`\n",
        "Let's create a new column named `text` that appends the instruction, text source and the summary that we can use for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nNkq7qd5mOSO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summarize the following academic content.\n",
              "\n",
              "Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising \n",
              "interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the \n",
              "properties of critical points and the landscape around them are of importance to determine the convergence \n",
              "performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of \n",
              "the analytical forms for the critical points <span style=\"font-weight: bold\">(</span>as well as global minimizers<span style=\"font-weight: bold\">)</span> of the square loss functions for linear\n",
              "neural networks. We show that the analytical forms of the critical points characterize the values of the \n",
              "corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. \n",
              "Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for \n",
              "the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While \n",
              "the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear\n",
              "networks with ReLU activation function does have local minimum that is not global minimum.\n",
              "\n",
              "Summary: We provide necessary and sufficient analytical forms for the critical points of the square loss functions \n",
              "for various neural networks, and exploit the analytical forms to characterize the landscape properties for the loss\n",
              "functions of these neural networks. <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">|endoftext|</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Summarize the following academic content.\n",
              "\n",
              "Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising \n",
              "interest in understanding loss functions for training neural networks from a theoretical aspect. Particularly, the \n",
              "properties of critical points and the landscape around them are of importance to determine the convergence \n",
              "performance of optimization algorithms. In this paper, we provide a necessary and sufficient characterization of \n",
              "the analytical forms for the critical points \u001b[1m(\u001b[0mas well as global minimizers\u001b[1m)\u001b[0m of the square loss functions for linear\n",
              "neural networks. We show that the analytical forms of the critical points characterize the values of the \n",
              "corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum. \n",
              "Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for \n",
              "the loss functions of linear neural networks and shallow ReLU networks. One particular conclusion is that: While \n",
              "the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear\n",
              "networks with ReLU activation function does have local minimum that is not global minimum.\n",
              "\n",
              "Summary: We provide necessary and sufficient analytical forms for the critical points of the square loss functions \n",
              "for various neural networks, and exploit the analytical forms to characterize the landscape properties for the loss\n",
              "functions of these neural networks. \u001b[1m<\u001b[0m\u001b[1;95m|endoftext|\u001b[0m\u001b[1m>\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt_template_with_response = \"\"\"Summarize the following academic content.\\n\n",
        "{source}\n",
        "\n",
        "Summary: {target} {eos_token}\"\"\"\n",
        "\n",
        "sample = dataset[\"train\"][0]\n",
        "text = prompt_template_with_response.format(source=\" \".join(sample[\"source\"]), target=\" \".join(sample[\"target\"]), eos_token = tokenizer.eos_token)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "krOaMKuym-AF"
      },
      "outputs": [],
      "source": [
        "def construct_text(batch):\n",
        "    \"\"\"Constructs a text from sources and targets with special prompt format for a summarization task.\n",
        "\n",
        "    Constructs a prompt by prepending a start prompt and appending an end prompt\n",
        "    to each source entry in the batch.\n",
        "\n",
        "    Args:\n",
        "        batch: A batch of source and target texts to tokenize.\n",
        "            The 'source' key should map to a list of source texts (each being a list of strings),\n",
        "            and the 'target' key should map to a list of target texts (each being a list of strings).\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing a new key named text\n",
        "    \"\"\"\n",
        "    ########################\n",
        "    # START YOUR CODE HERE #\n",
        "    ########################\n",
        "    # Replace None with your code\n",
        "\n",
        "    # Concatenate the source texts into single strings for each sample\n",
        "    sources = [src for src in batch['source']]\n",
        "\n",
        "    # Extract the first target text for each sample\n",
        "    targets = [target for target in batch[\"target\"]]\n",
        "\n",
        "    texts = []\n",
        "\n",
        "    for source, target in zip(sources,targets):\n",
        "      text = prompt_template_with_response.format(source=source, target=target, eos_token = tokenizer.eos_token)\n",
        "      texts.append(text)\n",
        "\n",
        "    batch[\"text\"] = texts\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxavbMOqpWQa"
      },
      "source": [
        "# Generate a text column\n",
        "\n",
        "Use dataset `map` function to generate a `text` column, remove all the remaining columns and verify one of the samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_3sc0d_5ySXn"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6963bceb733343788f05ec45b5b26c6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1992 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eda619e593b14488abe7ee5268041f5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/618 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8cec3eb91a94737a891aa1cf51d2938",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'text': \"Summarize the following academic content.\\n\\n['Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect.', 'Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.', 'In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks.', 'We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum.', 'Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks.', 'One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.']\\n\\nSummary: ['We provide necessary and sufficient analytical forms for the critical points of the square loss functions for various neural networks, and exploit the analytical forms to characterize the landscape properties for the loss functions of these neural networks.'] <|endoftext|>\"}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_with_text = dataset.map(construct_text, batched=True, remove_columns=dataset['train'].column_names)\n",
        "\n",
        "dataset_with_text[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtvUy2bAVN2Y"
      },
      "source": [
        "# Print the model to find attention blocks for LoRA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-8FS9s74Plm6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MixFormerSequentialForCausalLM</span><span style=\"font-weight: bold\">(</span>\n",
              "  <span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Sequential</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>wte<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51200</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ParallelBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>resid_dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mixer<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MHA</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">(</span>Wqkv<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6144</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SelfAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>inner_cross_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "          <span style=\"font-weight: bold\">(</span>drop<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MLP</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>fc2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">(</span>act<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">NewGELUActivation</span><span style=\"font-weight: bold\">()</span>\n",
              "      <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CausalLMHead</span><span style=\"font-weight: bold\">(</span>\n",
              "      <span style=\"font-weight: bold\">(</span>ln<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "      <span style=\"font-weight: bold\">(</span>linear<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51200</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">(</span>loss<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CausalLMLoss</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"font-weight: bold\">(</span>loss_fct<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossEntropyLoss</span><span style=\"font-weight: bold\">()</span>\n",
              "  <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mMixFormerSequentialForCausalLM\u001b[0m\u001b[1m(\u001b[0m\n",
              "  \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mwte\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m51200\u001b[0m, \u001b[1;36m2048\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mParallelBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mresid_dropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmixer\u001b[1m)\u001b[0m: \u001b[1;35mMHA\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mWqkv\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m6144\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mout_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_attn\u001b[1m)\u001b[0m: \u001b[1;35mSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0minner_cross_attn\u001b[1m)\u001b[0m: \u001b[1;35mCrossAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "          \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc1\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mfc2\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m8192\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m(\u001b[0mact\u001b[1m)\u001b[0m: \u001b[1;35mNewGELUActivation\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "    \u001b[1m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mCausalLMHead\u001b[0m\u001b[1m(\u001b[0m\n",
              "      \u001b[1m(\u001b[0mln\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "      \u001b[1m(\u001b[0mlinear\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m51200\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "  \u001b[1m(\u001b[0mloss\u001b[1m)\u001b[0m: \u001b[1;35mCausalLMLoss\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[1m(\u001b[0mloss_fct\u001b[1m)\u001b[0m: \u001b[1;35mCrossEntropyLoss\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# print the model here\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL7B1tT5zuMY"
      },
      "source": [
        "<a name='4'></a>\n",
        "# Configuring PEFT LORA\n",
        "<a name='4.1'></a>\n",
        "## Downloading and Converting Phi-1.5\n",
        "Now that the data is prepared for the training process, let's download and prepare the model!  This is much more straightforward.  We'll simply configure the LORA using a `LoraConfig` class with the following parameters:\n",
        "* `r = 8` This is the rank of the trainable LORA matrix.\n",
        "* `lora_alpha = 16` As a rule of thumb, set LoRA Alpha to be twice the rank.\n",
        "* `target_modules = ['Wqkv']` This is the layer of the transformer to apply LoRA for phi-1.5. You can find the modules by printing the model to stdout. This layer will be different for different models. You can provide a list of modules to apply LoRA.\n",
        "* `lora_dropout = 0.05` This is the dropout probability of the LoRA layers.\n",
        "* `bias = 'none'` This deactivates bias parameter training.\n",
        "* `task_type = TaskType.CAUSAL_LM` This informs the lora configuration that the model is a causal language model.\n",
        "\n",
        "One the LORA is configured, we'll apply it to the model using the `get_peft_model()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KCtZG-tm5p46"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# START YOUR CODE HERE #\n",
        "########################\n",
        "# Replace None with your code\n",
        "\n",
        "def create_lora_config():\n",
        "    lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules = ['Wqkv'],\n",
        "    r=8, \n",
        "    lora_alpha=16, \n",
        "    lora_dropout=0.05, \n",
        "    bias=\"none\"\n",
        "\n",
        "    )\n",
        "\n",
        "    return lora_config\n",
        "\n",
        "######################\n",
        "# END YOUR CODE HERE #\n",
        "######################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bXQCnwxk1pB3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.001s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Test your code!\n",
        "class TestLoraConfig(unittest.TestCase):\n",
        "    \"\"\"Unit tests for the LoraConfig class.\"\"\"\n",
        "\n",
        "    def test_lora_config_initialization(self):\n",
        "        \"\"\"Tests the initialization of LoraConfig with correct arguments.\"\"\"\n",
        "        lora_config = create_lora_config()\n",
        "\n",
        "        self.assertEqual(lora_config.r, 8)\n",
        "        self.assertEqual(lora_config.lora_alpha, 16)\n",
        "        self.assertEqual(lora_config.target_modules, {'Wqkv'})\n",
        "        self.assertEqual(lora_config.lora_dropout, 0.05)\n",
        "        self.assertEqual(lora_config.bias, \"none\")\n",
        "        self.assertEqual(lora_config.task_type, TaskType.CAUSAL_LM)\n",
        "\n",
        "# Run the tests\n",
        "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestLoraConfig))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jImO4oDU1pK4"
      },
      "outputs": [],
      "source": [
        "lora_config = create_lora_config()\n",
        "\n",
        "# Apply the LORA configuration to get a new model for PEFT\n",
        "peft_model = get_peft_model(model,\n",
        "                            lora_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysZCOAKr44Yx"
      },
      "source": [
        "<a name='4.2'></a>\n",
        "## Trainable Parameters\n",
        "Let's now compare the number of parameters in the model with the number of trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9Q0F-coj5GG4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Trainable model parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1572864</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Trainable model parameters: \u001b[1;36m1572864\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All model parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1419843584</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "All model parameters: \u001b[1;36m1419843584\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Percentage of trainable model parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11</span>%\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Percentage of trainable model parameters: \u001b[1;36m0.11\u001b[0m%\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    \"\"\"Prints the number of trainable parameters in the model.\n",
        "\n",
        "    This function traverses all the parameters of a given PyTorch model to\n",
        "    count the total number of parameters as well as the number of trainable\n",
        "    (i.e., requires gradient) parameters.\n",
        "\n",
        "    Args:\n",
        "        model: A PyTorch model whose parameters you want to count.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize counters for trainable and total parameters\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "\n",
        "    # Loop through all named parameters in the model\n",
        "    for _, param in model.named_parameters():\n",
        "        # Update the total number of parameters\n",
        "        all_model_params += param.numel()\n",
        "\n",
        "        # Check if the parameter requires gradient and update the trainable parameter counter\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "\n",
        "    # Calculate and print the number and percentage of trainable parameters\n",
        "    print(f\"Trainable model parameters: {trainable_model_params}\")\n",
        "    print(f\"All model parameters: {all_model_params}\")\n",
        "    print(f\"Percentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\")\n",
        "\n",
        "print_number_of_trainable_model_parameters(peft_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT-wv8UB5NU4"
      },
      "source": [
        "<a name='5'></a>\n",
        "# Training Configuration\n",
        "ALright, the data is ready ✅ and the LORA model is ready ✅, so our final step is to configure the training. Let's start with a baseline fo the following training arguments:\n",
        "* `learning_rate = 1e-3`: Specifies the learning rate for the optimizer.\n",
        "  \n",
        "* `num_train_epochs=1`: Indicates the number of times the entire training dataset is used to update the model weights. A value of 1 means each sample is used once to update the weights.\n",
        "\n",
        "* `logging_steps=50`: Specifies that logs for training metrics will be printed every 50 steps. Useful for monitoring the training process.\n",
        "\n",
        "* `evaluation_strategy=\"steps\"`: Specifies that the evaluation will be done based on the number of steps, as opposed to epochs. This is in line with `eval_steps`.\n",
        "\n",
        "* `eval_steps=200`: Indicates that the model will be evaluated every 200 training steps. This is only applicable if `evaluation_strategy` is set to `\"steps\"`.\n",
        "\n",
        "* `per_device_train_batch_size=1`: Defines the batch size for training on each device (e.g., GPU). A batch size of 1 means each training step updates the model based on a single sample.\n",
        "\n",
        "* `per_device_eval_batch_size=1`: Sets the batch size for evaluation on each device. Similar to the training batch size, a value of 1 means the model will be evaluated one sample at a time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RoAQRb_1t_oh"
      },
      "outputs": [],
      "source": [
        "output_dir = \"uplimit-project-3-phi-1.5\"\n",
        "\n",
        "########################\n",
        "# START YOUR CODE HERE #\n",
        "########################\n",
        "# Replace None with your code\n",
        "\n",
        "def create_peft_training_args():\n",
        "    peft_training_args = TrainingArguments(\n",
        "        output_dir=output_dir,  \n",
        "        learning_rate=1e-3,\n",
        "        num_train_epochs=1,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=200,\n",
        "        per_device_train_batch_size=1,\n",
        "        per_device_eval_batch_size=1,\n",
        "    )\n",
        "\n",
        "    return peft_training_args\n",
        "\n",
        "######################\n",
        "# END YOUR CODE HERE #\n",
        "######################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "id": "DxDRkd-O22Tc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.027s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Test your code\n",
        "\n",
        "class TestTrainingArguments(unittest.TestCase):\n",
        "    \"\"\"Unit tests for the TrainingArguments class.\"\"\"\n",
        "\n",
        "    def test_training_arguments_initialization(self):\n",
        "        \"\"\"Tests the initialization of TrainingArguments with correct arguments.\"\"\"\n",
        "        peft_training_args = create_peft_training_args()\n",
        "\n",
        "        self.assertEqual(peft_training_args.learning_rate, 1e-3)\n",
        "        self.assertEqual(peft_training_args.num_train_epochs, 1)\n",
        "        self.assertEqual(peft_training_args.logging_steps, 50)\n",
        "        self.assertEqual(peft_training_args.evaluation_strategy, \"steps\")\n",
        "        self.assertEqual(peft_training_args.eval_steps, 200)\n",
        "        self.assertEqual(peft_training_args.per_device_train_batch_size, 1)\n",
        "        self.assertEqual(peft_training_args.per_device_eval_batch_size, 1)\n",
        "\n",
        "# Run the tests\n",
        "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestTrainingArguments))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZtQilxt4blr"
      },
      "source": [
        "Now, create the SFT Trainer.  The trainer class contains all the information necessary to train a model, including:\n",
        "* `model = peft_model`: Of course, the trainer requires the model for training.\n",
        "* `args = peft_training_args`: These are the training arguments we defined earlier.\n",
        "* `train_dataset = dataset_with_text['train']`: We will use the `train` portion of the dataset for fine tuning.\n",
        "* `eval_dataset = dataset_with_text['validation']`: We will use the `validation` portion of the dataset to periodically evaluate our training progress.\n",
        "* `dataset_text_field = text`: dataset_text_field that corresponds to text containing prompt and its response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wo4wNsS_22bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Using pad_token, but it is not set yet.\n",
            "/Users/jessica-g/Documents/sleepypioneer/fine_tuning_LLMs/.env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:173: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bd8561b0c484a6ca58564cfb896cb4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1992 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b4d24d5c86f4caf9b5ec8506cc62b6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "peft_training_args = create_peft_training_args()\n",
        "\n",
        "########################\n",
        "# START YOUR CODE HERE #\n",
        "########################\n",
        "# Replace None with your code\n",
        "\n",
        "peft_trainer = SFTTrainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=dataset_with_text[\"train\"],\n",
        "    eval_dataset=dataset_with_text[\"validation\"],\n",
        "    dataset_text_field=\"text\",\n",
        ")\n",
        "\n",
        "######################\n",
        "# END YOUR CODE HERE #\n",
        "######################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jxH2G5J7QcK"
      },
      "source": [
        "<a name='6'></a>\n",
        "# Model Training\n",
        "\n",
        "These training arguments are verified to run properly on the free T4 GPUs available on Colab.  This training process will take under an hour.  If your notebook times out or you don't have enough time to train, we provide an option below to download the fine-tuned model from one of our course developers [here](https://huggingface.co/mrplants/arphiv).\n",
        "\n",
        "If you have some Colab credits available, this training process will take significantly less time using the V100 GPU (<15 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vYXvbkWkuFVw"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c8776e598564f22b3664d1e24d3b48d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1992 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.5251, 'learning_rate': 0.0009748995983935744, 'epoch': 0.03}\n",
            "{'loss': 2.4291, 'learning_rate': 0.0009497991967871486, 'epoch': 0.05}\n",
            "{'loss': 2.4759, 'learning_rate': 0.0009246987951807229, 'epoch': 0.08}\n",
            "{'loss': 2.4056, 'learning_rate': 0.0008995983935742972, 'epoch': 0.1}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "817b9c9b56eb47e2b1b8f5f8733332bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.495142698287964, 'eval_runtime': 484.2973, 'eval_samples_per_second': 1.278, 'eval_steps_per_second': 1.278, 'epoch': 0.1}\n",
            "{'loss': 2.422, 'learning_rate': 0.0008744979919678715, 'epoch': 0.13}\n",
            "{'loss': 2.4471, 'learning_rate': 0.0008493975903614458, 'epoch': 0.15}\n",
            "{'loss': 2.3673, 'learning_rate': 0.0008242971887550202, 'epoch': 0.18}\n",
            "{'loss': 2.4108, 'learning_rate': 0.0007991967871485943, 'epoch': 0.2}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d9c74b98b4f4e63973af69e506be0f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.4877090454101562, 'eval_runtime': 270.9763, 'eval_samples_per_second': 2.284, 'eval_steps_per_second': 2.284, 'epoch': 0.2}\n",
            "{'loss': 2.4476, 'learning_rate': 0.0007740963855421687, 'epoch': 0.23}\n",
            "{'loss': 2.351, 'learning_rate': 0.000748995983935743, 'epoch': 0.25}\n",
            "{'loss': 2.4081, 'learning_rate': 0.0007238955823293173, 'epoch': 0.28}\n",
            "{'loss': 2.3732, 'learning_rate': 0.0006987951807228916, 'epoch': 0.3}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56c7c33cfa094667a5d1899438371831",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.48234224319458, 'eval_runtime': 267.1099, 'eval_samples_per_second': 2.317, 'eval_steps_per_second': 2.317, 'epoch': 0.3}\n",
            "{'loss': 2.3098, 'learning_rate': 0.000673694779116466, 'epoch': 0.33}\n",
            "{'loss': 2.405, 'learning_rate': 0.0006485943775100401, 'epoch': 0.35}\n",
            "{'loss': 2.4131, 'learning_rate': 0.0006234939759036145, 'epoch': 0.38}\n",
            "{'loss': 2.4148, 'learning_rate': 0.0005983935742971888, 'epoch': 0.4}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05afe92d11914ad0856732121053ab1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.474083185195923, 'eval_runtime': 775.5813, 'eval_samples_per_second': 0.798, 'eval_steps_per_second': 0.798, 'epoch': 0.4}\n",
            "{'loss': 2.4392, 'learning_rate': 0.0005732931726907631, 'epoch': 0.43}\n",
            "{'loss': 2.4595, 'learning_rate': 0.0005481927710843374, 'epoch': 0.45}\n",
            "{'loss': 2.3861, 'learning_rate': 0.0005230923694779117, 'epoch': 0.48}\n",
            "{'loss': 2.3768, 'learning_rate': 0.0004979919678714859, 'epoch': 0.5}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa2693c2c56a4217b19850ee46177931",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.4746015071868896, 'eval_runtime': 285.1519, 'eval_samples_per_second': 2.171, 'eval_steps_per_second': 2.171, 'epoch': 0.5}\n",
            "{'loss': 2.3606, 'learning_rate': 0.00047289156626506026, 'epoch': 0.53}\n",
            "{'loss': 2.4252, 'learning_rate': 0.00044779116465863456, 'epoch': 0.55}\n",
            "{'loss': 2.2667, 'learning_rate': 0.0004226907630522088, 'epoch': 0.58}\n",
            "{'loss': 2.4095, 'learning_rate': 0.00039759036144578315, 'epoch': 0.6}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e999a6dd32e475785a6375adf263824",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.4631741046905518, 'eval_runtime': 282.8698, 'eval_samples_per_second': 2.188, 'eval_steps_per_second': 2.188, 'epoch': 0.6}\n",
            "{'loss': 2.445, 'learning_rate': 0.00037248995983935745, 'epoch': 0.63}\n",
            "{'loss': 2.3682, 'learning_rate': 0.0003473895582329317, 'epoch': 0.65}\n",
            "{'loss': 2.3838, 'learning_rate': 0.00032228915662650605, 'epoch': 0.68}\n",
            "{'loss': 2.3931, 'learning_rate': 0.0002971887550200803, 'epoch': 0.7}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffab06d686f0490083df40a2b9fa1891",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.4599523544311523, 'eval_runtime': 285.3502, 'eval_samples_per_second': 2.169, 'eval_steps_per_second': 2.169, 'epoch': 0.7}\n",
            "{'loss': 2.3535, 'learning_rate': 0.0002720883534136546, 'epoch': 0.73}\n",
            "{'loss': 2.3566, 'learning_rate': 0.0002469879518072289, 'epoch': 0.75}\n",
            "{'loss': 2.4198, 'learning_rate': 0.00022188755020080322, 'epoch': 0.78}\n",
            "{'loss': 2.3644, 'learning_rate': 0.00019678714859437752, 'epoch': 0.8}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db967868e919485d8603bbbb18408ae2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.4500410556793213, 'eval_runtime': 266.7208, 'eval_samples_per_second': 2.321, 'eval_steps_per_second': 2.321, 'epoch': 0.8}\n",
            "{'loss': 2.4057, 'learning_rate': 0.0001716867469879518, 'epoch': 0.83}\n",
            "{'loss': 2.3058, 'learning_rate': 0.0001465863453815261, 'epoch': 0.85}\n",
            "{'loss': 2.3329, 'learning_rate': 0.00012148594377510041, 'epoch': 0.88}\n",
            "{'loss': 2.4092, 'learning_rate': 9.638554216867471e-05, 'epoch': 0.9}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2096ec57bcc8486cae0a66bab16e9993",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/619 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.4488143920898438, 'eval_runtime': 267.5047, 'eval_samples_per_second': 2.314, 'eval_steps_per_second': 2.314, 'epoch': 0.9}\n",
            "{'loss': 2.3211, 'learning_rate': 7.1285140562249e-05, 'epoch': 0.93}\n",
            "{'loss': 2.3925, 'learning_rate': 4.618473895582329e-05, 'epoch': 0.95}\n",
            "{'loss': 2.305, 'learning_rate': 2.108433734939759e-05, 'epoch': 0.98}\n",
            "{'train_runtime': 5828.9958, 'train_samples_per_second': 0.342, 'train_steps_per_second': 0.342, 'train_loss': 2.391199268969187, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('uplimit-project-3-phi-1.5/tokenizer_config.json',\n",
              " 'uplimit-project-3-phi-1.5/special_tokens_map.json',\n",
              " 'uplimit-project-3-phi-1.5/vocab.json',\n",
              " 'uplimit-project-3-phi-1.5/merges.txt',\n",
              " 'uplimit-project-3-phi-1.5/added_tokens.json',\n",
              " 'uplimit-project-3-phi-1.5/tokenizer.json')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_trainer.train()\n",
        "\n",
        "peft_model_path=\"uplimit-project-3-phi-1.5\"\n",
        "\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zlF1kIhBDV2"
      },
      "source": [
        "<a name='7'></a>\n",
        "# Evaluation\n",
        "Now that the model training is complete, let's review the results using a couple samples from the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ei3A_gwZDrKW"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summarize the following academic content.\n",
              "\n",
              "Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This \n",
              "violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to \n",
              "suffer from catastrophic forgetting. Arguably, the best method for incremental class learning is iCaRL, but it \n",
              "requires storing  training examples for each class, making it challenging to scale. Here, we propose FearNet for \n",
              "incremental class learning. FearNet is a generative model that does not store previous examples, making it memory \n",
              "efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network \n",
              "for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by \n",
              "medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses\n",
              "a module inspired by the basolateral amygdala for determining which memory system to use for recall.   FearNet \n",
              "achieves state-of-the-art performance at incremental class learning on image <span style=\"font-weight: bold\">(</span>CIFAR-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, CUB-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span><span style=\"font-weight: bold\">)</span> and audio \n",
              "classification <span style=\"font-weight: bold\">(</span>AudioSet<span style=\"font-weight: bold\">)</span> benchmarks.\n",
              "\n",
              "\n",
              "Summary: \n",
              "</pre>\n"
            ],
            "text/plain": [
              "Summarize the following academic content.\n",
              "\n",
              "Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This \n",
              "violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to \n",
              "suffer from catastrophic forgetting. Arguably, the best method for incremental class learning is iCaRL, but it \n",
              "requires storing  training examples for each class, making it challenging to scale. Here, we propose FearNet for \n",
              "incremental class learning. FearNet is a generative model that does not store previous examples, making it memory \n",
              "efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network \n",
              "for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by \n",
              "medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses\n",
              "a module inspired by the basolateral amygdala for determining which memory system to use for recall.   FearNet \n",
              "achieves state-of-the-art performance at incremental class learning on image \u001b[1m(\u001b[0mCIFAR-\u001b[1;36m100\u001b[0m, CUB-\u001b[1;36m200\u001b[0m\u001b[1m)\u001b[0m and audio \n",
              "classification \u001b[1m(\u001b[0mAudioSet\u001b[1m)\u001b[0m benchmarks.\n",
              "\n",
              "\n",
              "Summary: \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">BASELINE HUMAN SUMMARY:\n",
              "FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable \n",
              "of incremental class learning without catastrophic forgetting.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "BASELINE HUMAN SUMMARY:\n",
              "FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable \n",
              "of incremental class learning without catastrophic forgetting.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PEFT MODEL SUMMARY:\n",
              " Fear Network 也不是克隆训练，老版会眏到相合起来没有很好的特性。你参阅道琎咑们対宫门字巺中所�ily进行一交话妊团员并\n",
              "</pre>\n"
            ],
            "text/plain": [
              "PEFT MODEL SUMMARY:\n",
              " Fear Network 也不是克隆训练，老版会眏到相合起来没有很好的特性。你参阅道琎咑们対宫门字巺中所�ily进行一交话妊团员并\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summarize the following academic content.\n",
              "\n",
              "Multi-view learning can provide self-supervision when different views are available of the same data. \n",
              "Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are \n",
              "plentiful in large unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the human brain as well\n",
              "as the observation that different learning architectures tend to emphasise different aspects of sentence meaning, \n",
              "we present two multi-view frameworks for learning sentence representations in an unsupervised fashion. One \n",
              "framework uses a generative objective and the other a discriminative one. In both frameworks, the final \n",
              "representation is an ensemble of two views, in which, one view encodes the input sentence with a Recurrent Neural \n",
              "Network <span style=\"font-weight: bold\">(</span>RNN<span style=\"font-weight: bold\">)</span>, and the other view encodes it with a simple linear model. We show that, after learning, the vectors \n",
              "produced by our multi-view frameworks provide improved representations over their single-view learnt counterparts, \n",
              "and the combination of different views gives representational improvement over each view and demonstrates solid \n",
              "transferability on standard downstream tasks.\n",
              "\n",
              "Summary: \n",
              "</pre>\n"
            ],
            "text/plain": [
              "Summarize the following academic content.\n",
              "\n",
              "Multi-view learning can provide self-supervision when different views are available of the same data. \n",
              "Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are \n",
              "plentiful in large unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the human brain as well\n",
              "as the observation that different learning architectures tend to emphasise different aspects of sentence meaning, \n",
              "we present two multi-view frameworks for learning sentence representations in an unsupervised fashion. One \n",
              "framework uses a generative objective and the other a discriminative one. In both frameworks, the final \n",
              "representation is an ensemble of two views, in which, one view encodes the input sentence with a Recurrent Neural \n",
              "Network \u001b[1m(\u001b[0mRNN\u001b[1m)\u001b[0m, and the other view encodes it with a simple linear model. We show that, after learning, the vectors \n",
              "produced by our multi-view frameworks provide improved representations over their single-view learnt counterparts, \n",
              "and the combination of different views gives representational improvement over each view and demonstrates solid \n",
              "transferability on standard downstream tasks.\n",
              "\n",
              "Summary: \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">BASELINE HUMAN SUMMARY:\n",
              "Multi-view learning improves unsupervised sentence representation learning\n",
              "</pre>\n"
            ],
            "text/plain": [
              "BASELINE HUMAN SUMMARY:\n",
              "Multi-view learning improves unsupervised sentence representation learning\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PEFT MODEL SUMMARY:\n",
              " We propose new methods based off theory developed around distributionally supervised inference along three \n",
              "spectrums - encoding hierarchical structures across multiple viewpoints; predicting semantic categories associated \n",
              "within these hierarchies using neural networks such  as recurrent or feedforward models instead ; combining several\n",
              "RNNs into sequence module rather than individual sequential embeddings. \n",
              "\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "PEFT MODEL SUMMARY:\n",
              " We propose new methods based off theory developed around distributionally supervised inference along three \n",
              "spectrums - encoding hierarchical structures across multiple viewpoints; predicting semantic categories associated \n",
              "within these hierarchies using neural networks such  as recurrent or feedforward models instead ; combining several\n",
              "RNNs into sequence module rather than individual sequential embeddings. \n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-----------------------------\n",
              "</pre>\n"
            ],
            "text/plain": [
              "-----------------------------\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = torch.device('mps')\n",
        "\n",
        "def generate_summary(source_content: str, model: AutoModelForCausalLM, tokenizer: AutoTokenizer) -> str:\n",
        "    \"\"\"Generates a summary for the given academic content using a pre-trained model.\n",
        "\n",
        "    Args:\n",
        "        source_content (str): The academic content to summarize.\n",
        "        model (AutoModelForCausalLM): The pretrained model used for text generation.\n",
        "        tokenizer (AutoTokenizer): The tokenizer used for encoding and decoding text.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated summary.\n",
        "    \"\"\"\n",
        "    prompt = prompt_template.format(source=source_content, bos_token = tokenizer.bos_token)\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "    outputs = model.generate(input_ids=input_ids,\n",
        "                             max_new_tokens=100,\n",
        "                             do_sample=True,\n",
        "                             temperature=0.7,\n",
        "                             repetition_penalty=1.5,\n",
        "                             eos_token_id=tokenizer.eos_token_id,\n",
        "                             pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    generated_ids = outputs[0][len(input_ids[0]):]\n",
        "    return tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "def evaluate_model_summary(index: int, dataset: dict, model: AutoModelForCausalLM, tokenizer: AutoTokenizer) -> None:\n",
        "    \"\"\"Evaluates and prints a model-generated summary against a human-created summary.\n",
        "\n",
        "    Args:\n",
        "        index (int): The index of the sample in the dataset to summarize.\n",
        "        dataset (dict): The dataset containing the academic content and human-created summaries.\n",
        "        model (AutoModelForCausalLM): The pretrained model used for text generation.\n",
        "        tokenizer (AutoTokenizer): The tokenizer used for encoding and decoding text.\n",
        "    \"\"\"\n",
        "    source_content = ' '.join(dataset['test'][index]['source'])\n",
        "    baseline_human_summary = dataset['test'][index]['target'][0]\n",
        "    peft_model_text_output = generate_summary(source_content, model, tokenizer)\n",
        "\n",
        "    print('-----------------------------')\n",
        "    print(f\"Summarize the following academic content.\\n\\n{source_content}\\n\\nSummary: \")\n",
        "    print('-----------------------------')\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
        "    print('-----------------------------')\n",
        "    print(f'PEFT MODEL SUMMARY:\\n{peft_model_text_output}')\n",
        "    print('-----------------------------')\n",
        "\n",
        "# Example usage\n",
        "evaluate_model_summary(0, dataset, peft_model, tokenizer)\n",
        "evaluate_model_summary(1, dataset, peft_model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "token = getpass.getpass(\"Enter your Hugging Face token: \")\n",
        "if len(token) <= 0:\n",
        "    raise ValueError(\"You need to set your Hugging Face token to upload your model to the Hub.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpW-itdJF-RA"
      },
      "source": [
        "If you're happy with the results, upload your LORA model to the HuggingFace Hub!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0EvGCrvSZT5H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /Users/jessica-g/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "M10P0ErHaHx8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "162af63fdc9d482cb575d8d06519807d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.bin:   0%|          | 0.00/6.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bda8477cb88c45fd8bb2c6c0370e49b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "058dc8988043451681d209afce79e5e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05ad47e05ecd49d0affd213ce42ecb9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Find your new model here:  <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://huggingface.co/jessica-ecosia/uplimit-project-3-phi-1.5/tree/main/</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Find your new model here:  \u001b[4;94mhttps://huggingface.co/jessica-ecosia/uplimit-project-3-phi-1.5/tree/main/\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_url = peft_trainer.push_to_hub()\n",
        "print(f'Find your new model here:  {model_url}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iouJ8fHz1jFf"
      },
      "source": [
        "# <a name='8'></a>\n",
        "# Real World Application\n",
        "Now let's try out our model on some data from the wild! The following code retrieves the abstract from a paper in the arXiv database and summarizes it using our model.\n",
        "\n",
        "# RESTART THE KERNEL IF YOU DON'T HAVE ENOUGH GPU MEMORY\n",
        "\n",
        "## Step 1: Download the PEFT model from the hub and create a new model\n",
        "\n",
        "Since the model that is uploaded to the hub is a LoRA model, it is much smaller (~25MB for phi 1.5) than the original model. Go and check the size on HF hub.\n",
        "\n",
        "In order to use this model for inference, we need to add LoRA weights to original model's weights.\n",
        "\n",
        "Below code shows the steps to download a LoRA model from hub and create a model ready for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DQR9sNTxk7C8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: transformers[torch]\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch] datasets peft einops trl --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QpuYZTTy0bQt"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e5b93161cab44a6a23481c6e5530b43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/adapter_config.json:   0%|          | 0.00/468 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98a2e542ad014b2f95288639eccbf7da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading adapter_model.bin:   0%|          | 0.00/6.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "########################\n",
        "# START YOUR CODE HERE #\n",
        "########################\n",
        "# Replace None with your code\n",
        "\n",
        "peft_model_id =  'jessica-ecosia/uplimit-project-3-phi-1.5'\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "inference_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, device_map=\"auto\", trust_remote_code=True)\n",
        "inference_tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Load the Lora model\n",
        "inference_model = PeftModel.from_pretrained(inference_model, peft_model_id)\n",
        "\n",
        "inference_tokenizer.pad_token_id = inference_tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAywOPeTGMbB"
      },
      "source": [
        "## Step 2: Download abstracts from arxiv and summarize them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HJIIeQPcBxPK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Abstract for paper 2103.00020:\n",
            "State-of-the-art computer vision systems are trained to predict a fixed set\n",
            "of predetermined object categories. This restricted form of supervision limits\n",
            "their generality and usability since additional labeled data is needed to\n",
            "specify any other visual concept. Learning directly from raw text about images\n",
            "is a promising alternative which leverages a much broader source of\n",
            "supervision. We demonstrate that the simple pre-training task of predicting\n",
            "which caption goes with which image is an efficient and scalable way to learn\n",
            "SOTA image representations from scratch on a dataset of 400 million (image,\n",
            "text) pairs collected from the internet. After pre-training, natural language\n",
            "is used to reference learned visual concepts (or describe new ones) enabling\n",
            "zero-shot transfer of the model to downstream tasks. We study the performance\n",
            "of this approach by benchmarking on over 30 different existing computer vision\n",
            "datasets, spanning tasks such as OCR, action recognition in videos,\n",
            "geo-localization, and many types of fine-grained object classification. The\n",
            "model transfers non-trivially to most tasks and is often competitive with a\n",
            "fully supervised baseline without the need for any dataset specific training.\n",
            "For instance, we match the accuracy of the original ResNet-50 on ImageNet\n",
            "zero-shot without needing to use any of the 1.28 million training examples it\n",
            "was trained on. We release our code and pre-trained model weights at\n",
            "https://github.com/OpenAI/CLIP.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def fetch_arxiv_abstract_by_id(arxiv_id: str) -> str:\n",
        "    \"\"\"Fetches the abstract of a paper from the arXiv database using its ID.\n",
        "\n",
        "    Args:\n",
        "        arxiv_id (str): The arXiv identifier for the paper.\n",
        "\n",
        "    Returns:\n",
        "        str: The abstract of the paper.\n",
        "    \"\"\"\n",
        "    # Construct the API URL for the arXiv paper\n",
        "    url = f'http://export.arxiv.org/api/query?id_list={arxiv_id}'\n",
        "\n",
        "    try:\n",
        "        # Fetch the XML data\n",
        "        response = urllib.request.urlopen(url)\n",
        "        xml_data = response.read().decode('utf-8')\n",
        "\n",
        "        # Parse the XML data\n",
        "        root = ET.fromstring(xml_data)\n",
        "\n",
        "        # Find the <summary> element which contains the abstract\n",
        "        for entry in root.find('{http://www.w3.org/2005/Atom}entry'):\n",
        "            if entry.tag == '{http://www.w3.org/2005/Atom}summary':\n",
        "                return entry.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "    return \"Abstract not found\"\n",
        "\n",
        "arxiv_id = \"2103.00020\"  # Replace with the arXiv ID of the paper you're interested in\n",
        "abstract = fetch_arxiv_abstract_by_id(arxiv_id)\n",
        "print()\n",
        "print(f\"Abstract for paper {arxiv_id}:\\n{abstract}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ-sqRVknFjK"
      },
      "source": [
        "## Step 3\n",
        "\n",
        "Create a prompt template and create an abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kDem5z1-k0Ww"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summarize the following academic content.\n",
            "\n",
            "State-of-the-art computer vision systems are trained to predict a fixed set\n",
            "of predetermined object categories. This restricted form of supervision limits\n",
            "their generality and usability since additional labeled data is needed to\n",
            "specify any other visual concept. Learning directly from raw text about images\n",
            "is a promising alternative which leverages a much broader source of\n",
            "supervision. We demonstrate that the simple pre-training task of predicting\n",
            "which caption goes with which image is an efficient and scalable way to learn\n",
            "SOTA image representations from scratch on a dataset of 400 million (image,\n",
            "text) pairs collected from the internet. After pre-training, natural language\n",
            "is used to reference learned visual concepts (or describe new ones) enabling\n",
            "zero-shot transfer of the model to downstream tasks. We study the performance\n",
            "of this approach by benchmarking on over 30 different existing computer vision\n",
            "datasets, spanning tasks such as OCR, action recognition in videos,\n",
            "geo-localization, and many types of fine-grained object classification. The\n",
            "model transfers non-trivially to most tasks and is often competitive with a\n",
            "fully supervised baseline without the need for any dataset specific training.\n",
            "For instance, we match the accuracy of the original ResNet-50 on ImageNet\n",
            "zero-shot without needing to use any of the 1.28 million training examples it\n",
            "was trained on. We release our code and pre-trained model weights at\n",
            "https://github.com/OpenAI/CLIP.\n",
            "\n",
            "Summary:\n"
          ]
        }
      ],
      "source": [
        "prompt_template = \"\"\"Summarize the following academic content.\\n\n",
        "{source}\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "prompt = prompt_template.format(source=abstract)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCTUeDtFnMqN"
      },
      "source": [
        "## Step 4: Use the model to summarize the abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XvNud8h7lIzh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TLDR target: \n",
            "\n",
            "    We present two stateless zero shot models based upon Natural Language Understanding\\n\" \"and Transfer learning using deep networks.\"\n",
            "\n",
            "   Reference paper link : https:/arxiv... /abs\\/180963856 \\r\\\\use\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('mps')\n",
        "\n",
        "input_ids = inference_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "outputs = inference_model.generate(input_ids=input_ids,\n",
        "                        max_new_tokens=50,\n",
        "                          do_sample=True,\n",
        "                          temperature=0.7,\n",
        "                          repetition_penalty=1.5,\n",
        "                          eos_token_id=inference_tokenizer.eos_token_id,\n",
        "                          pad_token_id=inference_tokenizer.pad_token_id)\n",
        "\n",
        "generated_ids = outputs[0][len(input_ids[0]):]\n",
        "summary = inference_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "print(\"TLDR target: \\n%s\"%summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUmNwgLiKiEX"
      },
      "source": [
        "<a name='9'></a>\n",
        "# Conclusion\n",
        "\n",
        "This project provided a comprehensive exploration into the realm of machine learning, specifically focusing on the application of Parameter-Efficient Fine-Tuning (PEFT) and Low Rank Adaptation (LORA) techniques. Utilizing the phi-1.5 model, we successfully fine-tuned it to generate concise and coherent summaries of scientific papers using the SciTLDR dataset from the Allen Institute for AI.\n",
        "\n",
        "Through the course of the project, we delved into various aspects such as data preprocessing and model trainingmetrics. Additionally, we explored ways to fetch real-world data from the arXiv database for practical testing. The project not only served as a hands-on experience in applying advanced NLP techniques but also laid the foundation for further research and development in automating the summarization of academic content."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
